{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#0b486b\">Part 3: Convolutional Neural Networks and Image Classification</span>\n",
    "\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[Total marks for this part: 40 points]</span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "This part of the asssignment is designed to assess your knowledge and coding skill with Tensorflow as well as hands-on experience with training Convolutional Neural Network (CNN).\n",
    "\n",
    "The dataset we use for this part is the [STL10 dataset](https://cs.stanford.edu/~acoates/stl10/) which consists of $5,000$ training images of airplane, bird, car, cat, deer, dog, horse, monkey, ship, truck; each of which has 500 images. You can download the dataset at [download here](https://drive.google.com/file/d/1bEwEx72lLrjY_Idj_FgV22atIdjtCV66/view?usp=sharing) and then decompress to the folder `datasets\\Animals` in your assignment folder.**\n",
    "\n",
    "Your task is to build a CNN model using *TF 2.x* to classify these animals. You're provided with the module <span style=\"color:red\">models.py</span>, which you can find in the assignment folder, with some of the following classes:\n",
    "\n",
    "1. `DatasetManager`: Support with loading and spliting the dataset into the train-val-test sets. It also supports generating next batches for training. \n",
    "2. `BaseImageClassifier`: A base class image classfication, which is basically a CNN model.\n",
    "\n",
    "*Note*: You may need to install the package `imutils` if you have not installed yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we need to run the following cells to load required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "from A1_S2_2023 import DatasetManager, BaseImageClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the class `DatasetManager` has attributes related to *the training, validation, and testing sets*. You can use them in training your developped models in the sequel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'stl10'\n",
    "# Choose path to store dataset\n",
    "data_dir = '{}/tensorflow_datasets'.format(os.path.expanduser('~'))\n",
    "\n",
    "data_manager = DatasetManager(dataset_name, data_dir)\n",
    "data_manager.load_dataset() \n",
    "data_manager.preprocess_dataset()\n",
    "data_manager.show_examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a random example\n",
    "import random\n",
    "num_examples = tf.data.experimental.cardinality(data_manager.ds_train).numpy()\n",
    "random_index = random.randint(0, num_examples - 1)\n",
    "example = next(iter(data_manager.ds_train.skip(random_index).take(1)))[0]\n",
    "\n",
    "# Print the shape and value of the image\n",
    "print(\"Image shape:\", example.shape)\n",
    "print(\"Image value range:\", example.numpy().min(), \"to\", example.numpy().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of examples in each dataset\n",
    "print(tf.data.experimental.cardinality(data_manager.ds_train))\n",
    "print(tf.data.experimental.cardinality(data_manager.ds_val))\n",
    "print(tf.data.experimental.cardinality(data_manager.ds_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use **BaseImageClassifier** built in the **A1_S2_2023.py** file which serves as a basic baseline to start the investigation. Follow the following steps to realize how to run a model and know the built-in methods associated with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network1 = BaseImageClassifier(name='network1',\n",
    "                       num_classes=10,\n",
    "                       optimizer='sgd',\n",
    "                       batch_size=128,\n",
    "                       num_epochs=20,\n",
    "                       learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first initialize a default model from the DefaultModel class. Basically, we can define the relevant parameters of training a model including `num_classes`, `optimizer`, `learning_rate`, `batch_size`, and `num_epochs`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method `build_cnn()` assists us in building your convolutional neural network. You can view the code (in the **A1_S2_2023.py** file) of the model behind a default model to realize how simple it is. Additionally, the method `summary()` shows the architecture of a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network1.build_cnn()\n",
    "network1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_batch = network1.optimize_data_pipeline(data_manager.ds_train, batch_size=32)\n",
    "x_val_batch = network1.optimize_data_pipeline(data_manager.ds_val, batch_size=32)\n",
    "network1.fit(x_train_batch, x_val_batch, num_epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train a model regarding to the datasets stored in `data_manager`, you can invoke the method `fit()` for which you can specify the batch size and number of epochs for your training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_batch = network1.optimize_data_pipeline(data_manager.ds_test, batch_size=32)\n",
    "network1.compute_accuracy(x_test_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below shows how you can inspect the training progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network1.plot_progress()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the method `predict()` to predict labels for data examples in a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 25\n",
    "sample_dataset = data_manager.ds_test.take(num_samples)\n",
    "network1.predict(sample_dataset.batch(num_samples), data_manager.ds_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the method `plot_prediction()` visualizes the predictions for a test set in which several images are chosen to show the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_samples = 20\n",
    "sample_dataset = data_manager.ds_test.take(num_samples)\n",
    "network1.plot_predictions(sample_dataset, data_manager.ds_info, num_samples=num_samples, grid_shape=(4, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\">Question 3.1: Observe the learning curve</span> \n",
    "After running the above cells to train the default model and observe the learning curve. Report your observation (i.e. did the model learn well? if not, what is the problem? What would you do to improve it?). Write your answer below.\n",
    "\n",
    "<div style=\"text-align: right\"> <span style=\"color:red\">[4 points]</span> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*# WRITE YOUR ANSWER AND OBSERVATION HERE*\n",
    "\n",
    ".....\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For questions 3.2 to 3.9**, you'll need to write your own model in a way that makes it easy for you to experiment with different architectures and parameters. The goal is to be able to pass the parameters to initialize a new instance of `YourModel` to build different network architectures with different parameters. Below are descriptions of some parameters which you can find in function `__init__()` for the class `BaseImageClassifier`:\n",
    "\n",
    "1. `num_blocks`: an integer specifying the number of blocks in our network. Each block has the pattern `[conv, batch norm, activation, conv, batch norm, activation, mean pool, dropout]`. All convolutional layers have filter size $(3, 3)$, strides $(1, 1)$ and 'SAME' padding, and all mean pool layers have strides $(2, 2)$ and 'SAME' padding. The network will consists of a few blocks before applying a linear layer to output the logits for the softmax layer.\n",
    "\n",
    "2. `feature_maps`: the number of feature maps in the first block of the network. The number of feature_maps will double in each of the following block. To make it convenient for you, we already calculated the number of feature maps for each block for you in line $106$\n",
    "3. `drop_rate`: the keep probability for dropout. Setting `drop_rate` to $0.0$ means not using dropout. \n",
    "4. `batch_norm`: the batch normalization function is used or not. Setting `batch_norm` to `None` means not using batch normalization. \n",
    "5. The `skip connection` is added to the output of the second `batch norm`. Additionally, your class has a boolean property (i.e., instance variable) named `use_skip`. If `use_skip=True`, the skip connectnion is enable. Otherwise, if `use_skip=False`, the skip connectnion is disable.\n",
    "\n",
    "Below is the architecture of one block:\n",
    "\n",
    "<img src=\"Figures/OneBlock.png\" width=\"350\" align=\"center\"/>\n",
    "\n",
    "Below is the architecture of the entire deep net with `two blocks`:\n",
    "\n",
    "<img src=\"Figures/NetworkArchitecture.png\" width=\"1200\" align=\"center\"/>\n",
    "\n",
    "Here we assume that the first block has `feature_maps = feature_maps[0] = 32`. Note that the initial number of feature maps of the first block is declared in the instance variable `feature_maps` and is multiplied by $2$ in each follpwing block. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "tf.random.set_seed(3181)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\">Question 3.2: Define your CNN</span>\n",
    "\n",
    "Write the code of the `YourModel` class here. Note that this class will be inherited from the `BaseImageClassifier` class. You'll only need to re-write the code for the `build_cnn` method in the `YourModel` class from the cell below.\n",
    "\n",
    "<div style=\"text-align: right\"> <span style=\"color:red\">[4 points]</span> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YourModel(BaseImageClassifier):\n",
    "    def __init__(self,\n",
    "                 name='network1',\n",
    "                 width=32, height=32, depth=3,\n",
    "                 num_blocks=2,\n",
    "                 feature_maps=32,\n",
    "                 num_classes=4,\n",
    "                 drop_rate=0.2,\n",
    "                 batch_norm=None,\n",
    "                 is_augmentation=False,\n",
    "                 activation_func='relu',\n",
    "                 optimizer='adam',\n",
    "                 use_skip=True,\n",
    "                 batch_size=10,\n",
    "                 num_epochs=20,\n",
    "                 learning_rate=0.0001,\n",
    "                 verbose=True):\n",
    "        super(YourModel, self).__init__(name, width, height, depth, num_blocks, feature_maps, num_classes, drop_rate, batch_norm, is_augmentation, \n",
    "                                        activation_func, use_skip, optimizer, batch_size, num_epochs, learning_rate, verbose)\n",
    "    \n",
    "    def build_cnn(self):\n",
    "        # INSERT YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\">Question 3.3: Experiment with skip connection</span> \n",
    "Once writing your own model, you need to compare two cases: (i) *using the skip connection* and (ii) *not using the skip connection*. You should set the instance variable `use_skip` to either `True` or `False`. For your runs, report which case is better and if you confront overfitting in training.\n",
    "    \n",
    "<div style=\"text-align: right\"> <span style=\"color:red\">[6 points]</span> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*# WRITE YOUR ANSWER AND OBSERVATION HERE*\n",
    "\n",
    ".....\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_network_skip = YourModel(name='network1',\n",
    "                     feature_maps=32,\n",
    "                     num_classes=data_manager.n_classes,\n",
    "                     num_blocks=3,\n",
    "                     drop_rate=0.0, \n",
    "                     batch_norm=True, \n",
    "                     use_skip=True,\n",
    "                     optimizer='sgd',\n",
    "                     learning_rate=0.001)\n",
    "our_network_skip.build_cnn()\n",
    "our_network_skip.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_network_skip.fit(x_train_batch, x_val_batch, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_network_no_skip = YourModel(name='network1',\n",
    "                     feature_maps=32,\n",
    "                     num_classes=data_manager.n_classes,\n",
    "                     num_blocks=3,\n",
    "                     drop_rate=0.0, \n",
    "                     batch_norm=True, \n",
    "                     use_skip=False,\n",
    "                     optimizer='sgd',\n",
    "                     learning_rate=0.001)\n",
    "our_network_no_skip.build_cnn()\n",
    "our_network_no_skip.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_network_no_skip.fit(x_train_batch, x_val_batch, num_epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\">Question 3.4: Tune hyperparameters with grid search</span>\n",
    "\n",
    "Now, let us tune the $num\\_blocks \\in \\{2,3,4\\}$, $use\\_skip \\in \\{True, False\\}$, and $learning\\_rate \\in \\{0.001, 0.0001\\}$. Write your code for this tuning and report the result of the best model on the testing set. Note that you need to show your code for tuning and evaluating on the test set to earn the full marks. During tuning, you can set the instance variable `verbose` of your model to `False` for not showing the training details of each epoch.\n",
    " \n",
    "<div style=\"text-align: right\"> <span style=\"color:red\">[4 points]</span> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*# REPORT THE BEST PARAMETERS AND THE TESTING ACCURACY HERE*\n",
    "\n",
    "....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOU ARE REQUIRED TO INSERT YOUR CODES IN THIS CELL\n",
    "# You can add more cells if necessary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\">Question 3.5: Apply data augmentation</span>\n",
    "\n",
    "We now try to apply data augmentation to improve the performance. Extend the code of the class `YourModel` so that if the attribute `is_augmentation` is set to `True`, we apply the data augmentation. Also you need to incorporate early stopping to your training process. Specifically, you early stop the training if the valid accuracy cannot increase in three consecutive epochs.\n",
    "   \n",
    "<div style=\"text-align: right\"> <span style=\"color:red\">[4 points]</span> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wtire your code in the cell below. Hint that you can rewrite the code of the `fit` method to apply the data augmentation. In addition, you can copy the code of `build_cnn` method above to reuse here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YourModel(DefaultModel):\n",
    "    def __init__(self,\n",
    "                 name='network1',\n",
    "                 width=32, height=32, depth=3,\n",
    "                 num_blocks=2,\n",
    "                 feature_maps=32,\n",
    "                 num_classes=4, \n",
    "                 drop_rate=0.2,\n",
    "                 batch_norm = None,\n",
    "                 is_augmentation = False,\n",
    "                 activation_func='relu',\n",
    "                 use_skip = True,\n",
    "                 optimizer='adam',\n",
    "                 batch_size=10,\n",
    "                 num_epochs= 20,\n",
    "                 learning_rate=0.0001):\n",
    "        super(YourModel, self).__init__(name, width, height, depth, num_blocks, feature_maps, num_classes, drop_rate, batch_norm, is_augmentation, \n",
    "                                        activation_func, use_skip, optimizer, batch_size, num_epochs, learning_rate)\n",
    "    \n",
    "    def build_cnn(self):\n",
    "        # INSERT YOUR CODE HERE\n",
    "    \n",
    "    def fit(self, data_manager, batch_size=None, num_epochs=None):\n",
    "        # INSERT YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\">Question 3.6: Observe model performance with data augmentation</span>\n",
    "\n",
    "Leverage your best model with the data augmentation and try to observe the difference in performance between using data augmentation and not using it.\n",
    "   \n",
    "<div style=\"text-align: right\"> <span style=\"color:red\">[4 points]</span> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*# WRITE YOUR ANSWER AND OBSERVATION HERE*\n",
    "\n",
    "....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOU ARE REQUIRED TO INSERT YOUR CODES IN THIS CELL\n",
    "# You can add more cells if necessary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\">Question 3.7: Explore data mixup technique</span>\n",
    "\n",
    "<div style=\"text-align: right\"> <span style=\"color:red\">[4 points]</span> </div>\n",
    "\n",
    "Data mixup is another super-simple technique used to boost the generalization ability of deep learning models. You need to incoroporate data mixup technique to the above deep learning model and experiment its performance. There are some papers and documents for data mixup as follows:\n",
    "- Main paper for data mixup [link for main paper](https://openreview.net/pdf?id=r1Ddp1-Rb) and a good article [article link](https://www.inference.vc/mixup-data-dependent-data-augmentation/).\n",
    "\n",
    "You need to extend your model developed above, train a model using data mixup, and write your observations and comments about the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*# WRITE YOUR ANSWER AND OBSERVATION HERE*\n",
    "\n",
    ".....\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOU ARE REQUIRED TO INSERT YOUR CODES IN THIS CELL\n",
    "# You can add more cells if necessary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For questions **3.8 and 3.9**, you can reuse code in lectures or labs. You should not use third-party libraries such as ClevenHans."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <span style=\"color:#0b486b\">Question 3.8: Attack your model</span>\n",
    "\n",
    "Attack your best obtained model with PGD, MIM, and FGSM attacks with $\\epsilon= 0.0313, k=20, \\eta= 0.002$ on the testing set. Write the code for the attacks and report the robust accuracies. Also choose a random set of 20 clean images in the testing set and visualize the original and attacked images.\n",
    "   \n",
    "<div style=\"text-align: right\"> <span style=\"color:red\">[5 points]</span> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOU ARE REQUIRED TO INSERT YOUR CODES IN THIS CELL\n",
    "# You can add more cells if necessary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\">Question 3.9: Train a robust model</span>\n",
    "\n",
    "Train a robust model using adversarial training with PGD ${\\epsilon= 0.0313, k=10, \\eta= 0.002}$. Write the code for the adversarial training and report the robust accuracies. After finishing the training, you need to store your best robust model in the folder `./models` and load the model to evaluate the robust accuracies for PGD, MIM, and FGSM attacks with $\\epsilon= 0.0313, k=20, \\eta= 0.002$ on the testing set.\n",
    "   \n",
    "<div style=\"text-align: right\"> <span style=\"color:red\">[5 points]</span> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOU ARE REQUIRED TO INSERT YOUR CODES IN THIS CELL\n",
    "# You can add more cells if necessary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is an exploring question with bonus points. It is great if you try to do this question, but it is **totally optional**. In this question, we will investigate a recent SOTA technique to improve the generalization ability of deep nets named *Sharpness-Aware Minimization (SAM)* ([link to the main paper](https://openreview.net/pdf?id=6Tm1mposlrM)).  Furthermore, SAM is simple and efficient technique, but roughly doubles the training time due to its required computation. If you have an idea to improve SAM, it would be a great paper to top-tier venues in machine learning and computer vision. Highly recommend to give it a try. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\">Question 3.10</span> (bonus question)\n",
    "\n",
    "Read the SAM paper ([link to the main paper](https://openreview.net/pdf?id=6Tm1mposlrM)). Try to apply this technique to the best obtained model and report the results. For the purpose of implementing SAM, we can flexibly add more cells and extensions to the `model.py` file.\n",
    "\n",
    "<div style=\"text-align: right\"> <span style=\"color:red\">[5 points]</span> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOU ARE REQUIRED TO INSERT YOUR CODES IN THIS CELL\n",
    "# You can add more cells if necessary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "**<div style=\"text-align: center\"> <span style=\"color:black\">END OF ASSIGNMENT</span> </div>**\n",
    "**<div style=\"text-align: center\"> <span style=\"color:black\">GOOD LUCK WITH YOUR ASSIGNMENT 1!</span> </div>**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FIT3181",
   "language": "python",
   "name": "fit3181"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
